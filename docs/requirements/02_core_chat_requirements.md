# 基础对话通道 - 需求分析文档

**模块**: 第三阶段 - AI 对话核心  
**功能**: 基础对话通道  
**版本**: v1.0  
**日期**: 2026-01-30

---

## 1. 业务背景

Coca AI 的核心功能是提供类似 ChatGPT 的 AI 对话体验。用户登录后可以与 AI 进行多轮对话，系统需要支持流式响应（打字机效果）、对话历史存储和上下文管理。

---

## 2. 用户故事

| ID | 用户故事 | 优先级 |
|----|---------|--------|
| US-01 | 作为用户，我希望创建新的对话会话，以便开始一个新话题 | P0 |
| US-02 | 作为用户，我希望发送消息并实时看到 AI 逐字回复（打字机效果） | P0 |
| US-03 | 作为用户，我希望查看当前会话的历史消息 | P0 |
| US-04 | 作为用户，我希望查看我的所有历史会话列表 | P1 |
| US-05 | 作为用户，我希望删除某个历史会话 | P2 |

---

## 3. 功能性需求

### 3.1 LLM 服务接入

| 需求ID | 描述 |
|--------|------|
| FR-01 | 使用 **Eino 框架** 对接 **通义千问** 大模型 |
| FR-02 | 支持流式响应 (Streaming)，逐 Token 返回 |
| FR-03 | 支持配置 System Prompt（系统人设） |
| FR-04 | 抽象 LLM 接口，便于未来切换模型 |

**Eino 框架核心组件**:
- `ChatModel`: 与 LLM 交互的核心组件
- `ChatTemplate`: 管理 Prompt 模板
- `Retriever`: (RAG 阶段使用) 获取上下文

### 3.2 对话会话管理

| 需求ID | 描述 |
|--------|------|
| FR-05 | 用户可以创建新会话 (Session) |
| FR-06 | 每个会话包含多条消息 (Message) |
| FR-07 | 消息角色: `user`, `assistant`, `system` |
| FR-08 | 会话标题自动生成（基于首条用户消息） |

### 3.3 智能上下文管理

| 需求ID | 描述 |
|--------|------|
| FR-09 | 采用 **摘要压缩 + 语义检索** 混合策略管理上下文 |
| FR-10 | System Prompt 始终保留在上下文首位 |
| FR-11 | Token 计数检查，确保不超过模型限制 |
| FR-12 | 历史消息超过阈值时，使用 LLM 生成摘要替代原文 |
| FR-13 | (RAG 阶段) 历史消息存入向量库，按语义相关性检索补充上下文 |

**上下文构建流程**:
```
1. 保留 System Prompt
2. 保留最近 K 条消息 (K=10)
3. 如果历史 > K:
   a. 对 K 之前的消息生成摘要 (调用 LLM)
   b. 将摘要作为 "历史总结" 插入上下文
4. (可选) 从向量库检索与当前问题相关的历史片段
5. 组装最终 Prompt 发送给 LLM
```

### 3.4 数据存储与消息队列

| 需求ID | 描述 |
|--------|------|
| FR-14 | **Redis**: 存储活跃会话消息（热数据，TTL 24h） |
| FR-15 | **MySQL**: 持久化存储会话和消息（冷数据） |
| FR-16 | **Kafka**: 异步消息处理，解耦写入操作 |
| FR-17 | 消息发送后: 立即写入 Redis -> 发送到 Kafka -> Consumer 落库 MySQL |

**消息流转架构**:
```
用户发送消息
      │
      ▼
┌─────────────────┐
│ 1. 写入 Redis   │  ← 实时可读
└─────────────────┘
      │
      ▼
┌─────────────────┐
│ 2. 发送 Kafka   │  ← Topic: chat.messages
└─────────────────┘
      │
      ▼
┌─────────────────┐
│ 3. Consumer     │  ← 异步消费
│    落库 MySQL   │
└─────────────────┘
```

### 3.5 API 接口

| 需求ID | 接口 | 描述 |
|--------|------|------|
| FR-18 | `POST /chat/sessions` | 创建新会话 |
| FR-19 | `GET /chat/sessions` | 获取用户会话列表 |
| FR-20 | `GET /chat/sessions/:id/messages` | 获取会话历史消息 |
| FR-21 | `POST /chat/sessions/:id/messages` | 发送消息 (SSE 流式响应) |
| FR-22 | `DELETE /chat/sessions/:id` | 删除会话 |

---

## 4. 非功能性需求

| 需求ID | 描述 |
|--------|------|
| NFR-01 | SSE 响应延迟 < 500ms（首个 Token） |
| NFR-02 | 支持并发对话请求（至少 100 并发） |
| NFR-03 | 消息存储不丢失（Redis 写入 + MySQL 落库） |

---

## 5. 数据模型 (概念)

### Session (会话)
| 字段 | 类型 | 描述 |
|------|------|------|
| id | int64 | 会话 ID |
| user_id | int64 | 所属用户 |
| title | string | 会话标题 |
| created_at | timestamp | 创建时间 |
| updated_at | timestamp | 最后更新时间 |

### Message (消息)
| 字段 | 类型 | 描述 |
|------|------|------|
| id | int64 | 消息 ID |
| session_id | int64 | 所属会话 |
| role | string | user / assistant / system |
| content | text | 消息内容 |
| created_at | timestamp | 创建时间 |

---

## 6. 技术选型确认

| 组件 | 选型 | 理由 |
|------|------|------|
| LLM 框架 | **Eino (CloudWeGo)** | 字节跳动开源，Go 原生，经过豆包/抖音验证 |
| LLM 模型 | **通义千问** | 国内模型，稳定可用 |
| 流式协议 | **SSE (Server-Sent Events)** | 浏览器原生支持，实现简单 |
| 消息队列 | **Kafka** | 高吞吐、持久化、支持多消费者 |
| 热存储 | **Redis** | 高性能读写，TTL 自动过期 |
| 冷存储 | **MySQL** | 持久化，支持复杂查询 |

---

## 7. 技术选型论证

### 7.1 为什么需要 Redis？

| 问题 | 不用 Redis 的后果 | 用 Redis 如何缓解 |
|------|------------------|------------------|
| **读取延迟** | 每次发送消息都需要从 MySQL 读取历史消息构建上下文，MySQL 磁盘 IO 较慢，响应延迟高 | Redis 内存读取，延迟 < 1ms，大幅提升用户体验 |
| **数据库压力** | 高并发场景下，频繁读取 MySQL 会导致连接池耗尽、QPS 瓶颈 | Redis 承担热数据读取，MySQL 只处理冷数据查询 |
| **会话状态管理** | 无法高效管理活跃会话状态 | Redis TTL 自动清理过期会话缓存 |

**结论**: Redis 作为**热数据缓存层**，解决读取性能问题。

### 7.2 为什么需要 Kafka？

| 问题 | 不用 Kafka 的后果 | 用 Kafka 如何缓解 |
|------|------------------|------------------|
| **请求阻塞** | 消息发送后同步写入 MySQL，如果 MySQL 慢或宕机，用户请求会卡住甚至失败 | Kafka 异步解耦，用户请求立即返回，后台慢慢消费落库 |
| **数据丢失** | 如果服务重启或崩溃，内存中待写入的消息会丢失 | Kafka 消息持久化，即使 Consumer 宕机也能重新消费 |
| **流量削峰** | 突发流量直接打到 MySQL，可能导致数据库崩溃 | Kafka 缓冲消息，Consumer 按自己的速度消费 |
| **扩展性** | 单体架构无法水平扩展 | 多个 Consumer 可以并行消费，实现水平扩展 |

**结论**: Kafka 作为**异步消息队列**，解决写入解耦、可靠性和扩展性问题。

### 7.3 为什么使用摘要压缩而非滑动窗口？

| 问题 | 滑动窗口的缺点 | 摘要压缩的优势 |
|------|---------------|---------------|
| **上下文丢失** | 简单截断会丢失重要历史信息，导致 AI "失忆" | 摘要保留历史精髓，AI 仍能理解之前的对话背景 |
| **用户体验** | 用户问"我之前说过什么"，AI 无法回答 | 摘要包含历史要点，AI 可以回顾之前内容 |
| **Token 利用** | 固定 N 条消息可能浪费 Token 或不够用 | 摘要压缩后更高效利用 Token 窗口 |

**结论**: 摘要压缩 + 语义检索是更智能的上下文管理方案。

### 7.4 架构演进路径

```
Phase 1 (MVP):        无缓存直连 MySQL
                            ↓
Phase 2 (当前):       Redis 缓存 + Kafka 异步
                            ↓
Phase 3 (RAG):        + Milvus 向量检索
                            ↓
Phase 4 (高可用):     + 多副本 + 分布式事务
```

---

## 8. 风险与假设

| 风险 | 影响 | 缓解措施 |
|------|------|---------|
| 通义千问 API 不稳定 | 用户体验下降 | 添加重试机制和超时控制 |
| Eino 框架文档不完善 | 开发效率降低 | 参考官方示例和源码 |
| Token 超限 | 请求失败 | 滑动窗口 + Token 计数预检 |

---

## 9. 验收标准

- [ ] 用户可以创建新会话
- [ ] 发送消息后，AI 以流式方式逐字回复
- [ ] 刷新页面后，历史消息仍然存在
- [ ] 上下文超过 10 条时，历史摘要被正确生成
